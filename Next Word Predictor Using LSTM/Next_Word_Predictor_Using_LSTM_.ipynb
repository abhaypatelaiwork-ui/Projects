{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYova1sLqqcd"
      },
      "outputs": [],
      "source": [
        "faqs = \"\"\"Why LSTM Exists (Problem First)\n",
        "\n",
        "Classic RNNs fail at long-term dependencies because of:\n",
        "\n",
        "Vanishing gradients\n",
        "\n",
        "Exploding gradients\n",
        "\n",
        "üëâ They forget information that‚Äôs far back in time.\n",
        "\n",
        "LSTM (Long Short-Term Memory) fixes this by controlling what to remember, forget, and output.\n",
        "\n",
        "2Ô∏è‚É£ Core Idea (One Line)\n",
        "\n",
        "LSTM uses gates + a memory cell to selectively store long-term information.\n",
        "\n",
        "Think of it as:\n",
        "\n",
        "Memory cell = long-term storage\n",
        "\n",
        "Gates = smart controllers\n",
        "\n",
        "3Ô∏è‚É£ LSTM Architecture (Inside the Cell)\n",
        "\n",
        "At time step t, LSTM has:\n",
        "\n",
        "Input: x‚Çú\n",
        "\n",
        "Hidden state: h‚Çú‚Çã‚ÇÅ\n",
        "\n",
        "Cell state: c‚Çú‚Çã‚ÇÅ\n",
        "\n",
        "üîπ 1. Forget Gate\n",
        "\n",
        "Decides what to erase from memory.\n",
        "\n",
        "ùëì\n",
        "ùë°\n",
        "=\n",
        "ùúé\n",
        "(\n",
        "ùëä\n",
        "ùëì\n",
        "[\n",
        "‚Ñé\n",
        "ùë°\n",
        "‚àí\n",
        "1\n",
        ",\n",
        "ùë•\n",
        "ùë°\n",
        "]\n",
        "+\n",
        "ùëè\n",
        "ùëì\n",
        ")\n",
        "f\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "=œÉ(W\n",
        "f\n",
        "\t‚Äã\n",
        "\n",
        "[h\n",
        "t‚àí1\n",
        "\t‚Äã\n",
        "\n",
        ",x\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "]+b\n",
        "f\n",
        "\t‚Äã\n",
        "\n",
        ")\n",
        "\n",
        "Output: values in [0,1]\n",
        "\n",
        "0 ‚Üí forget completely\n",
        "\n",
        "1 ‚Üí keep everything\n",
        "\n",
        "üîπ 2. Input Gate\n",
        "\n",
        "Decides what new information to store.\n",
        "\n",
        "ùëñ\n",
        "ùë°\n",
        "=\n",
        "ùúé\n",
        "(\n",
        "ùëä\n",
        "ùëñ\n",
        "[\n",
        "‚Ñé\n",
        "ùë°\n",
        "‚àí\n",
        "1\n",
        ",\n",
        "ùë•\n",
        "ùë°\n",
        "]\n",
        "+\n",
        "ùëè\n",
        "ùëñ\n",
        ")\n",
        "i\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "=œÉ(W\n",
        "i\n",
        "\t‚Äã\n",
        "\n",
        "[h\n",
        "t‚àí1\n",
        "\t‚Äã\n",
        "\n",
        ",x\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "]+b\n",
        "i\n",
        "\t‚Äã\n",
        "\n",
        ")\n",
        "ùëê\n",
        "~\n",
        "ùë°\n",
        "=\n",
        "tanh\n",
        "‚Å°\n",
        "(\n",
        "ùëä\n",
        "ùëê\n",
        "[\n",
        "‚Ñé\n",
        "ùë°\n",
        "‚àí\n",
        "1\n",
        ",\n",
        "ùë•\n",
        "ùë°\n",
        "]\n",
        "+\n",
        "ùëè\n",
        "ùëê\n",
        ")\n",
        "c\n",
        "~\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "=tanh(W\n",
        "c\n",
        "\t‚Äã\n",
        "\n",
        "[h\n",
        "t‚àí1\n",
        "\t‚Äã\n",
        "\n",
        ",x\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "]+b\n",
        "c\n",
        "\t‚Äã\n",
        "\n",
        ")\n",
        "üîπ 3. Cell State Update (Most Important)\n",
        "ùëê\n",
        "ùë°\n",
        "=\n",
        "ùëì\n",
        "ùë°\n",
        "‚äô\n",
        "ùëê\n",
        "ùë°\n",
        "‚àí\n",
        "1\n",
        "+\n",
        "ùëñ\n",
        "ùë°\n",
        "‚äô\n",
        "ùëê\n",
        "~\n",
        "ùë°\n",
        "c\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "=f\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "‚äôc\n",
        "t‚àí1\n",
        "\t‚Äã\n",
        "\n",
        "+i\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "‚äô\n",
        "c\n",
        "~\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "\n",
        "‚úÖ This linear path allows gradients to flow ‚Üí no vanishing gradient\n",
        "\n",
        "üîπ 4. Output Gate\n",
        "\n",
        "Decides what to output.\n",
        "\n",
        "ùëú\n",
        "ùë°\n",
        "=\n",
        "ùúé\n",
        "(\n",
        "ùëä\n",
        "ùëú\n",
        "[\n",
        "‚Ñé\n",
        "ùë°\n",
        "‚àí\n",
        "1\n",
        ",\n",
        "ùë•\n",
        "ùë°\n",
        "]\n",
        "+\n",
        "ùëè\n",
        "ùëú\n",
        ")\n",
        "o\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "=œÉ(W\n",
        "o\n",
        "\t‚Äã\n",
        "\n",
        "[h\n",
        "t‚àí1\n",
        "\t‚Äã\n",
        "\n",
        ",x\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "]+b\n",
        "o\n",
        "\t‚Äã\n",
        "\n",
        ")\n",
        "‚Ñé\n",
        "ùë°\n",
        "=\n",
        "ùëú\n",
        "ùë°\n",
        "‚äô\n",
        "tanh\n",
        "‚Å°\n",
        "(\n",
        "ùëê\n",
        "ùë°\n",
        ")\n",
        "h\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "=o\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "‚äôtanh(c\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        ")\n",
        "4Ô∏è‚É£ Why LSTM Works So Well\n",
        "\n",
        "Cell state acts like a highway for gradients\n",
        "\n",
        "Gates prevent unnecessary updates\n",
        "\n",
        "Can remember dependencies 100s of steps back\n",
        "\n",
        "That‚Äôs the real magic üß†\n",
        "\n",
        "5Ô∏è‚É£ LSTM vs RNN vs GRU\n",
        "Feature\tRNN\tLSTM\tGRU\n",
        "Long memory\t‚ùå\t‚úÖ\t‚úÖ\n",
        "Gates\t‚ùå\t3 gates\t2 gates\n",
        "Parameters\tLow\tHigh\tMedium\n",
        "Training speed\tFast\tSlow\tFaster\n",
        "\n",
        "üëâ GRU = simpler LSTM (used when data is limited)\n",
        "\n",
        "6Ô∏è‚É£ Variants You Should Know\n",
        "\n",
        "Important for interviews + research:\n",
        "\n",
        "Bi-LSTM ‚Üí context from past & future\n",
        "\n",
        "Stacked LSTM ‚Üí deeper representations\n",
        "\n",
        "ConvLSTM ‚Üí video & spatiotemporal data\n",
        "\n",
        "Attention + LSTM ‚Üí pre-Transformer era SOTA\n",
        "\n",
        "7Ô∏è‚É£ Practical Uses (Still Relevant in 2026)\n",
        "\n",
        "Despite Transformers, LSTMs are used in:\n",
        "\n",
        "‚è± Time-series forecasting (stocks, sensors)\n",
        "\n",
        "üß† Healthcare (ECG, EEG signals)\n",
        "\n",
        "üîä Speech processing (low-latency systems)\n",
        "\n",
        "üè≠ Edge devices (less compute than Transformers)\n",
        "\n",
        "8Ô∏è‚É£ Common Pitfalls (Real Projects)\n",
        "\n",
        "Needs proper sequence scaling\n",
        "\n",
        "Slow on very long sequences\n",
        "\n",
        "Sensitive to batch size & learning rate\n",
        "\n",
        "Hard to parallelize (vs Transformers)\n",
        "\n",
        "9Ô∏è‚É£ Interview-Level One-Liner\n",
        "\n",
        "‚ÄúLSTM solves vanishing gradients by using a gated cell state that allows selective memory retention over long sequences.‚Äù\n",
        "\n",
        "Memorize this üí°\n",
        "\n",
        "üîü When NOT to Use LSTM\n",
        "\n",
        "‚ùå Very long documents\n",
        "‚ùå NLP tasks with massive data\n",
        "‚ùå When parallelization is needed\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "o9wZQSIOq8C2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "VhZIjfqlq82s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "pPEHyFwvrEz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_1cDdmrQIt",
        "outputId": "dbaaa23d-010f-438d-a68a-a31f9ef95b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "252"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qzt5SU0ZrWq9",
        "outputId": "08d16ea5-6c19-4cfa-a216-08f237773553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\u200b': 1,\n",
              " 'ùë°': 2,\n",
              " 't': 3,\n",
              " 'lstm': 4,\n",
              " 'to': 5,\n",
              " 'long': 6,\n",
              " '1': 7,\n",
              " 'cell': 8,\n",
              " '‚Üí': 9,\n",
              " 'ùëê': 10,\n",
              " 'memory': 11,\n",
              " 'gates': 12,\n",
              " 'c': 13,\n",
              " 'gradients': 14,\n",
              " 'state': 15,\n",
              " '‚Ñé': 16,\n",
              " '‚àí': 17,\n",
              " 'h': 18,\n",
              " 't‚àí1': 19,\n",
              " '‚ùå': 20,\n",
              " 'term': 21,\n",
              " 'forget': 22,\n",
              " 'in': 23,\n",
              " 'what': 24,\n",
              " 'output': 25,\n",
              " 'üîπ': 26,\n",
              " 'ùëì': 27,\n",
              " 'ùëä': 28,\n",
              " 'ùë•': 29,\n",
              " 'ùëè': 30,\n",
              " 'f': 31,\n",
              " 'w': 32,\n",
              " 'x': 33,\n",
              " 'b': 34,\n",
              " 'ùëñ': 35,\n",
              " 'i': 36,\n",
              " '‚äô': 37,\n",
              " 'ùëú': 38,\n",
              " 'o': 39,\n",
              " 'of': 40,\n",
              " 'vanishing': 41,\n",
              " 'information': 42,\n",
              " 'time': 43,\n",
              " 'this': 44,\n",
              " 'a': 45,\n",
              " 'gate': 46,\n",
              " 'decides': 47,\n",
              " 'ùúé': 48,\n",
              " 'œÉ': 49,\n",
              " 'tanh': 50,\n",
              " '‚úÖ': 51,\n",
              " 'vs': 52,\n",
              " 'gru': 53,\n",
              " 'when': 54,\n",
              " 'data': 55,\n",
              " 'transformers': 56,\n",
              " 'why': 57,\n",
              " 'at': 58,\n",
              " 'dependencies': 59,\n",
              " 'üëâ': 60,\n",
              " 'that‚Äôs': 61,\n",
              " 'back': 62,\n",
              " 'by': 63,\n",
              " 'remember': 64,\n",
              " 'one': 65,\n",
              " 'uses': 66,\n",
              " 'store': 67,\n",
              " 'the': 68,\n",
              " 'input': 69,\n",
              " 'from': 70,\n",
              " '0': 71,\n",
              " '2': 72,\n",
              " '\\u2061': 73,\n",
              " '3': 74,\n",
              " 'important': 75,\n",
              " 'allows': 76,\n",
              " 'for': 77,\n",
              " 'real': 78,\n",
              " 'üß†': 79,\n",
              " 'rnn': 80,\n",
              " 'low': 81,\n",
              " 'slow': 82,\n",
              " 'used': 83,\n",
              " 'is': 84,\n",
              " 'very': 85,\n",
              " 'sequences': 86,\n",
              " 'exists': 87,\n",
              " 'problem': 88,\n",
              " 'first': 89,\n",
              " 'classic': 90,\n",
              " 'rnns': 91,\n",
              " 'fail': 92,\n",
              " 'because': 93,\n",
              " 'exploding': 94,\n",
              " 'they': 95,\n",
              " 'far': 96,\n",
              " 'short': 97,\n",
              " 'fixes': 98,\n",
              " 'controlling': 99,\n",
              " 'and': 100,\n",
              " '2Ô∏è‚É£': 101,\n",
              " 'core': 102,\n",
              " 'idea': 103,\n",
              " 'line': 104,\n",
              " 'selectively': 105,\n",
              " 'think': 106,\n",
              " 'it': 107,\n",
              " 'as': 108,\n",
              " 'storage': 109,\n",
              " 'smart': 110,\n",
              " 'controllers': 111,\n",
              " '3Ô∏è‚É£': 112,\n",
              " 'architecture': 113,\n",
              " 'inside': 114,\n",
              " 'step': 115,\n",
              " 'has': 116,\n",
              " 'x‚Çú': 117,\n",
              " 'hidden': 118,\n",
              " 'h‚Çú‚Çã‚ÇÅ': 119,\n",
              " 'c‚Çú‚Çã‚ÇÅ': 120,\n",
              " 'erase': 121,\n",
              " 'values': 122,\n",
              " 'completely': 123,\n",
              " 'keep': 124,\n",
              " 'everything': 125,\n",
              " 'new': 126,\n",
              " 'update': 127,\n",
              " 'most': 128,\n",
              " '‚äôc': 129,\n",
              " 'linear': 130,\n",
              " 'path': 131,\n",
              " 'flow': 132,\n",
              " 'no': 133,\n",
              " 'gradient': 134,\n",
              " '4': 135,\n",
              " '‚äôtanh': 136,\n",
              " '4Ô∏è‚É£': 137,\n",
              " 'works': 138,\n",
              " 'so': 139,\n",
              " 'well': 140,\n",
              " 'acts': 141,\n",
              " 'like': 142,\n",
              " 'highway': 143,\n",
              " 'prevent': 144,\n",
              " 'unnecessary': 145,\n",
              " 'updates': 146,\n",
              " 'can': 147,\n",
              " '100s': 148,\n",
              " 'steps': 149,\n",
              " 'magic': 150,\n",
              " '5Ô∏è‚É£': 151,\n",
              " 'feature': 152,\n",
              " 'parameters': 153,\n",
              " 'high': 154,\n",
              " 'medium': 155,\n",
              " 'training': 156,\n",
              " 'speed': 157,\n",
              " 'fast': 158,\n",
              " 'faster': 159,\n",
              " 'simpler': 160,\n",
              " 'limited': 161,\n",
              " '6Ô∏è‚É£': 162,\n",
              " 'variants': 163,\n",
              " 'you': 164,\n",
              " 'should': 165,\n",
              " 'know': 166,\n",
              " 'interviews': 167,\n",
              " 'research': 168,\n",
              " 'bi': 169,\n",
              " 'context': 170,\n",
              " 'past': 171,\n",
              " 'future': 172,\n",
              " 'stacked': 173,\n",
              " 'deeper': 174,\n",
              " 'representations': 175,\n",
              " 'convlstm': 176,\n",
              " 'video': 177,\n",
              " 'spatiotemporal': 178,\n",
              " 'attention': 179,\n",
              " 'pre': 180,\n",
              " 'transformer': 181,\n",
              " 'era': 182,\n",
              " 'sota': 183,\n",
              " '7Ô∏è‚É£': 184,\n",
              " 'practical': 185,\n",
              " 'still': 186,\n",
              " 'relevant': 187,\n",
              " '2026': 188,\n",
              " 'despite': 189,\n",
              " 'lstms': 190,\n",
              " 'are': 191,\n",
              " '‚è±': 192,\n",
              " 'series': 193,\n",
              " 'forecasting': 194,\n",
              " 'stocks': 195,\n",
              " 'sensors': 196,\n",
              " 'healthcare': 197,\n",
              " 'ecg': 198,\n",
              " 'eeg': 199,\n",
              " 'signals': 200,\n",
              " 'üîä': 201,\n",
              " 'speech': 202,\n",
              " 'processing': 203,\n",
              " 'latency': 204,\n",
              " 'systems': 205,\n",
              " 'üè≠': 206,\n",
              " 'edge': 207,\n",
              " 'devices': 208,\n",
              " 'less': 209,\n",
              " 'compute': 210,\n",
              " 'than': 211,\n",
              " '8Ô∏è‚É£': 212,\n",
              " 'common': 213,\n",
              " 'pitfalls': 214,\n",
              " 'projects': 215,\n",
              " 'needs': 216,\n",
              " 'proper': 217,\n",
              " 'sequence': 218,\n",
              " 'scaling': 219,\n",
              " 'on': 220,\n",
              " 'sensitive': 221,\n",
              " 'batch': 222,\n",
              " 'size': 223,\n",
              " 'learning': 224,\n",
              " 'rate': 225,\n",
              " 'hard': 226,\n",
              " 'parallelize': 227,\n",
              " '9Ô∏è‚É£': 228,\n",
              " 'interview': 229,\n",
              " 'level': 230,\n",
              " 'liner': 231,\n",
              " '‚Äúlstm': 232,\n",
              " 'solves': 233,\n",
              " 'using': 234,\n",
              " 'gated': 235,\n",
              " 'that': 236,\n",
              " 'selective': 237,\n",
              " 'retention': 238,\n",
              " 'over': 239,\n",
              " '‚Äù': 240,\n",
              " 'memorize': 241,\n",
              " 'üí°': 242,\n",
              " 'üîü': 243,\n",
              " 'not': 244,\n",
              " 'use': 245,\n",
              " 'documents': 246,\n",
              " 'nlp': 247,\n",
              " 'tasks': 248,\n",
              " 'with': 249,\n",
              " 'massive': 250,\n",
              " 'parallelization': 251,\n",
              " 'needed': 252}"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in faqs.split('\\n'):\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3c5stxzsHOa",
        "outputId": "0c9e4927-19c0-4e27-e532-ef7e1bd67b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why LSTM Exists (Problem First)\n",
            "\n",
            "Classic RNNs fail at long-term dependencies because of:\n",
            "\n",
            "Vanishing gradients\n",
            "\n",
            "Exploding gradients\n",
            "\n",
            "üëâ They forget information that‚Äôs far back in time.\n",
            "\n",
            "LSTM (Long Short-Term Memory) fixes this by controlling what to remember, forget, and output.\n",
            "\n",
            "2Ô∏è‚É£ Core Idea (One Line)\n",
            "\n",
            "LSTM uses gates + a memory cell to selectively store long-term information.\n",
            "\n",
            "Think of it as:\n",
            "\n",
            "Memory cell = long-term storage\n",
            "\n",
            "Gates = smart controllers\n",
            "\n",
            "3Ô∏è‚É£ LSTM Architecture (Inside the Cell)\n",
            "\n",
            "At time step t, LSTM has:\n",
            "\n",
            "Input: x‚Çú\n",
            "\n",
            "Hidden state: h‚Çú‚Çã‚ÇÅ\n",
            "\n",
            "Cell state: c‚Çú‚Çã‚ÇÅ\n",
            "\n",
            "üîπ 1. Forget Gate\n",
            "\n",
            "Decides what to erase from memory.\n",
            "\n",
            "ùëì\n",
            "ùë°\n",
            "=\n",
            "ùúé\n",
            "(\n",
            "ùëä\n",
            "ùëì\n",
            "[\n",
            "‚Ñé\n",
            "ùë°\n",
            "‚àí\n",
            "1\n",
            ",\n",
            "ùë•\n",
            "ùë°\n",
            "]\n",
            "+\n",
            "ùëè\n",
            "ùëì\n",
            ")\n",
            "f\n",
            "t\n",
            "\t‚Äã\n",
            "\n",
            "=œÉ(W\n",
            "f\n",
            "\t‚Äã\n",
            "\n",
            "[h\n",
            "t‚àí1\n",
            "\t‚Äã\n",
            "\n",
            ",x\n",
            "t\n",
            "\t‚Äã\n",
            "\n",
            "]+b\n",
            "f\n",
            "\t‚Äã\n",
            "\n",
            ")\n",
            "\n",
            "Output: values in [0,1]\n",
            "\n",
            "0 ‚Üí forget completely\n",
            "\n",
            "1 ‚Üí keep everything\n",
            "\n",
            "üîπ 2. Input Gate\n",
            "\n",
            "Decides what new information to store.\n",
            "\n",
            "ùëñ\n",
            "ùë°\n",
            "=\n",
            "ùúé\n",
            "(\n",
            "ùëä\n",
            "ùëñ\n",
            "[\n",
            "‚Ñé\n",
            "ùë°\n",
            "‚àí\n",
            "1\n",
            ",\n",
            "ùë•\n",
            "ùë°\n",
            "]\n",
            "+\n",
            "ùëè\n",
            "ùëñ\n",
            ")\n",
            "i\n",
            "t\n",
            "\t‚Äã\n",
            "\n",
            "=œÉ(W\n",
            "i\n",
            "\t‚Äã\n",
            "\n",
            "[h\n",
            "t‚àí1\n",
            "\t‚Äã\n",
            "\n",
            ",x\n",
            "t\n",
            "\t‚Äã\n",
            "\n",
            "]+b\n",
            "i\n",
            "\t‚Äã\n",
            "\n",
            ")\n",
            "ùëê\n",
            "~\n",
            "ùë°\n",
            "=\n",
            "tanh\n",
            "‚Å°\n",
            "(\n",
            "ùëä\n",
            "ùëê\n",
            "[\n",
            "‚Ñé\n",
            "ùë°\n",
            "‚àí\n",
            "1\n",
            ",\n",
            "ùë•\n",
            "ùë°\n",
            "]\n",
            "+\n",
            "ùëè\n",
            "ùëê\n",
            ")\n",
            "c\n",
            "~\n",
            "t\n",
            "\t‚Äã\n",
            "\n",
            "=tanh(W\n",
            "c\n",
            "\t‚Äã\n",
            "\n",
            "[h\n",
            "t‚àí1\n",
            "\t‚Äã\n",
            "\n",
            ",x\n",
            "t\n",
            "\t‚Äã\n",
            "\n",
            "]+b\n",
            "c\n",
            "\t‚Äã\n",
            "\n",
            ")\n",
            "üîπ 3. Cell State Update (Most Important)\n",
            "ùëê\n",
            "ùë°\n",
            "=\n",
            "ùëì\n",
            "ùë°\n",
            "‚äô\n",
            "ùëê\n",
            "ùë°\n",
            "‚àí\n",
            "1\n",
            "+\n",
            "ùëñ\n",
            "ùë°\n",
            "‚äô\n",
            "ùëê\n",
            "~\n",
            "ùë°\n",
            "c\n",
            "t\n",
            "\t‚Äã\n",
            "\n",
            "=f\n",
            "t\n",
            "\t‚Äã\n",
            "\n",
            "‚äôc\n",
            "t‚àí1\n",
            "\t‚Äã\n",
            "\n",
            "+i\n",
            "t\n",
            "\t‚Äã\n",
            "\n",
            "‚äô\n",
            "c\n",
            "~\n",
            "t\n",
            "\t‚Äã\n",
            "\n",
            "\n",
            "‚úÖ This linear path allows gradients to flow ‚Üí no vanishing gradient\n",
            "\n",
            "üîπ 4. Output Gate\n",
            "\n",
            "Decides what to output.\n",
            "\n",
            "ùëú\n",
            "ùë°\n",
            "=\n",
            "ùúé\n",
            "(\n",
            "ùëä\n",
            "ùëú\n",
            "[\n",
            "‚Ñé\n",
            "ùë°\n",
            "‚àí\n",
            "1\n",
            ",\n",
            "ùë•\n",
            "ùë°\n",
            "]\n",
            "+\n",
            "ùëè\n",
            "ùëú\n",
            ")\n",
            "o\n",
            "t\n",
            "\t‚Äã\n",
            "\n",
            "=œÉ(W\n",
            "o\n",
            "\t‚Äã\n",
            "\n",
            "[h\n",
            "t‚àí1\n",
            "\t‚Äã\n",
            "\n",
            ",x\n",
            "t\n",
            "\t‚Äã\n",
            "\n",
            "]+b\n",
            "o\n",
            "\t‚Äã\n",
            "\n",
            ")\n",
            "‚Ñé\n",
            "ùë°\n",
            "=\n",
            "ùëú\n",
            "ùë°\n",
            "‚äô\n",
            "tanh\n",
            "‚Å°\n",
            "(\n",
            "ùëê\n",
            "ùë°\n",
            ")\n",
            "h\n",
            "t\n",
            "\t‚Äã\n",
            "\n",
            "=o\n",
            "t\n",
            "\t‚Äã\n",
            "\n",
            "‚äôtanh(c\n",
            "t\n",
            "\t‚Äã\n",
            "\n",
            ")\n",
            "4Ô∏è‚É£ Why LSTM Works So Well\n",
            "\n",
            "Cell state acts like a highway for gradients\n",
            "\n",
            "Gates prevent unnecessary updates\n",
            "\n",
            "Can remember dependencies 100s of steps back\n",
            "\n",
            "That‚Äôs the real magic üß†\n",
            "\n",
            "5Ô∏è‚É£ LSTM vs RNN vs GRU\n",
            "Feature\tRNN\tLSTM\tGRU\n",
            "Long memory\t‚ùå\t‚úÖ\t‚úÖ\n",
            "Gates\t‚ùå\t3 gates\t2 gates\n",
            "Parameters\tLow\tHigh\tMedium\n",
            "Training speed\tFast\tSlow\tFaster\n",
            "\n",
            "üëâ GRU = simpler LSTM (used when data is limited)\n",
            "\n",
            "6Ô∏è‚É£ Variants You Should Know\n",
            "\n",
            "Important for interviews + research:\n",
            "\n",
            "Bi-LSTM ‚Üí context from past & future\n",
            "\n",
            "Stacked LSTM ‚Üí deeper representations\n",
            "\n",
            "ConvLSTM ‚Üí video & spatiotemporal data\n",
            "\n",
            "Attention + LSTM ‚Üí pre-Transformer era SOTA\n",
            "\n",
            "7Ô∏è‚É£ Practical Uses (Still Relevant in 2026)\n",
            "\n",
            "Despite Transformers, LSTMs are used in:\n",
            "\n",
            "‚è± Time-series forecasting (stocks, sensors)\n",
            "\n",
            "üß† Healthcare (ECG, EEG signals)\n",
            "\n",
            "üîä Speech processing (low-latency systems)\n",
            "\n",
            "üè≠ Edge devices (less compute than Transformers)\n",
            "\n",
            "8Ô∏è‚É£ Common Pitfalls (Real Projects)\n",
            "\n",
            "Needs proper sequence scaling\n",
            "\n",
            "Slow on very long sequences\n",
            "\n",
            "Sensitive to batch size & learning rate\n",
            "\n",
            "Hard to parallelize (vs Transformers)\n",
            "\n",
            "9Ô∏è‚É£ Interview-Level One-Liner\n",
            "\n",
            "‚ÄúLSTM solves vanishing gradients by using a gated cell state that allows selective memory retention over long sequences.‚Äù\n",
            "\n",
            "Memorize this üí°\n",
            "\n",
            "üîü When NOT to Use LSTM\n",
            "\n",
            "‚ùå Very long documents\n",
            "‚ùå NLP tasks with massive data\n",
            "‚ùå When parallelization is needed\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in faqs.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "  print(tokenized_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcDcgmzgsMtC",
        "outputId": "133aa929-9209-4d04-c48d-35f679ea1ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[57, 4, 87, 88, 89]\n",
            "[]\n",
            "[90, 91, 92, 58, 6, 21, 59, 93, 40]\n",
            "[]\n",
            "[41, 14]\n",
            "[]\n",
            "[94, 14]\n",
            "[]\n",
            "[60, 95, 22, 42, 61, 96, 62, 23, 43]\n",
            "[]\n",
            "[4, 6, 97, 21, 11, 98, 44, 63, 99, 24, 5, 64, 22, 100, 25]\n",
            "[]\n",
            "[101, 102, 103, 65, 104]\n",
            "[]\n",
            "[4, 66, 12, 45, 11, 8, 5, 105, 67, 6, 21, 42]\n",
            "[]\n",
            "[106, 40, 107, 108]\n",
            "[]\n",
            "[11, 8, 6, 21, 109]\n",
            "[]\n",
            "[12, 110, 111]\n",
            "[]\n",
            "[112, 4, 113, 114, 68, 8]\n",
            "[]\n",
            "[58, 43, 115, 3, 4, 116]\n",
            "[]\n",
            "[69, 117]\n",
            "[]\n",
            "[118, 15, 119]\n",
            "[]\n",
            "[8, 15, 120]\n",
            "[]\n",
            "[26, 7, 22, 46]\n",
            "[]\n",
            "[47, 24, 5, 121, 70, 11]\n",
            "[]\n",
            "[27]\n",
            "[2]\n",
            "[]\n",
            "[48]\n",
            "[]\n",
            "[28]\n",
            "[27]\n",
            "[]\n",
            "[16]\n",
            "[2]\n",
            "[17]\n",
            "[7]\n",
            "[]\n",
            "[29]\n",
            "[2]\n",
            "[]\n",
            "[]\n",
            "[30]\n",
            "[27]\n",
            "[]\n",
            "[31]\n",
            "[3]\n",
            "[1]\n",
            "[]\n",
            "[49, 32]\n",
            "[31]\n",
            "[1]\n",
            "[]\n",
            "[18]\n",
            "[19]\n",
            "[1]\n",
            "[]\n",
            "[33]\n",
            "[3]\n",
            "[1]\n",
            "[]\n",
            "[34]\n",
            "[31]\n",
            "[1]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[25, 122, 23, 71, 7]\n",
            "[]\n",
            "[71, 9, 22, 123]\n",
            "[]\n",
            "[7, 9, 124, 125]\n",
            "[]\n",
            "[26, 72, 69, 46]\n",
            "[]\n",
            "[47, 24, 126, 42, 5, 67]\n",
            "[]\n",
            "[35]\n",
            "[2]\n",
            "[]\n",
            "[48]\n",
            "[]\n",
            "[28]\n",
            "[35]\n",
            "[]\n",
            "[16]\n",
            "[2]\n",
            "[17]\n",
            "[7]\n",
            "[]\n",
            "[29]\n",
            "[2]\n",
            "[]\n",
            "[]\n",
            "[30]\n",
            "[35]\n",
            "[]\n",
            "[36]\n",
            "[3]\n",
            "[1]\n",
            "[]\n",
            "[49, 32]\n",
            "[36]\n",
            "[1]\n",
            "[]\n",
            "[18]\n",
            "[19]\n",
            "[1]\n",
            "[]\n",
            "[33]\n",
            "[3]\n",
            "[1]\n",
            "[]\n",
            "[34]\n",
            "[36]\n",
            "[1]\n",
            "[]\n",
            "[]\n",
            "[10]\n",
            "[]\n",
            "[2]\n",
            "[]\n",
            "[50]\n",
            "[73]\n",
            "[]\n",
            "[28]\n",
            "[10]\n",
            "[]\n",
            "[16]\n",
            "[2]\n",
            "[17]\n",
            "[7]\n",
            "[]\n",
            "[29]\n",
            "[2]\n",
            "[]\n",
            "[]\n",
            "[30]\n",
            "[10]\n",
            "[]\n",
            "[13]\n",
            "[]\n",
            "[3]\n",
            "[1]\n",
            "[]\n",
            "[50, 32]\n",
            "[13]\n",
            "[1]\n",
            "[]\n",
            "[18]\n",
            "[19]\n",
            "[1]\n",
            "[]\n",
            "[33]\n",
            "[3]\n",
            "[1]\n",
            "[]\n",
            "[34]\n",
            "[13]\n",
            "[1]\n",
            "[]\n",
            "[]\n",
            "[26, 74, 8, 15, 127, 128, 75]\n",
            "[10]\n",
            "[2]\n",
            "[]\n",
            "[27]\n",
            "[2]\n",
            "[37]\n",
            "[10]\n",
            "[2]\n",
            "[17]\n",
            "[7]\n",
            "[]\n",
            "[35]\n",
            "[2]\n",
            "[37]\n",
            "[10]\n",
            "[]\n",
            "[2]\n",
            "[13]\n",
            "[3]\n",
            "[1]\n",
            "[]\n",
            "[31]\n",
            "[3]\n",
            "[1]\n",
            "[]\n",
            "[129]\n",
            "[19]\n",
            "[1]\n",
            "[]\n",
            "[36]\n",
            "[3]\n",
            "[1]\n",
            "[]\n",
            "[37]\n",
            "[13]\n",
            "[]\n",
            "[3]\n",
            "[1]\n",
            "[]\n",
            "[]\n",
            "[51, 44, 130, 131, 76, 14, 5, 132, 9, 133, 41, 134]\n",
            "[]\n",
            "[26, 135, 25, 46]\n",
            "[]\n",
            "[47, 24, 5, 25]\n",
            "[]\n",
            "[38]\n",
            "[2]\n",
            "[]\n",
            "[48]\n",
            "[]\n",
            "[28]\n",
            "[38]\n",
            "[]\n",
            "[16]\n",
            "[2]\n",
            "[17]\n",
            "[7]\n",
            "[]\n",
            "[29]\n",
            "[2]\n",
            "[]\n",
            "[]\n",
            "[30]\n",
            "[38]\n",
            "[]\n",
            "[39]\n",
            "[3]\n",
            "[1]\n",
            "[]\n",
            "[49, 32]\n",
            "[39]\n",
            "[1]\n",
            "[]\n",
            "[18]\n",
            "[19]\n",
            "[1]\n",
            "[]\n",
            "[33]\n",
            "[3]\n",
            "[1]\n",
            "[]\n",
            "[34]\n",
            "[39]\n",
            "[1]\n",
            "[]\n",
            "[]\n",
            "[16]\n",
            "[2]\n",
            "[]\n",
            "[38]\n",
            "[2]\n",
            "[37]\n",
            "[50]\n",
            "[73]\n",
            "[]\n",
            "[10]\n",
            "[2]\n",
            "[]\n",
            "[18]\n",
            "[3]\n",
            "[1]\n",
            "[]\n",
            "[39]\n",
            "[3]\n",
            "[1]\n",
            "[]\n",
            "[136, 13]\n",
            "[3]\n",
            "[1]\n",
            "[]\n",
            "[]\n",
            "[137, 57, 4, 138, 139, 140]\n",
            "[]\n",
            "[8, 15, 141, 142, 45, 143, 77, 14]\n",
            "[]\n",
            "[12, 144, 145, 146]\n",
            "[]\n",
            "[147, 64, 59, 148, 40, 149, 62]\n",
            "[]\n",
            "[61, 68, 78, 150, 79]\n",
            "[]\n",
            "[151, 4, 52, 80, 52, 53]\n",
            "[152, 80, 4, 53]\n",
            "[6, 11, 20, 51, 51]\n",
            "[12, 20, 74, 12, 72, 12]\n",
            "[153, 81, 154, 155]\n",
            "[156, 157, 158, 82, 159]\n",
            "[]\n",
            "[60, 53, 160, 4, 83, 54, 55, 84, 161]\n",
            "[]\n",
            "[162, 163, 164, 165, 166]\n",
            "[]\n",
            "[75, 77, 167, 168]\n",
            "[]\n",
            "[169, 4, 9, 170, 70, 171, 172]\n",
            "[]\n",
            "[173, 4, 9, 174, 175]\n",
            "[]\n",
            "[176, 9, 177, 178, 55]\n",
            "[]\n",
            "[179, 4, 9, 180, 181, 182, 183]\n",
            "[]\n",
            "[184, 185, 66, 186, 187, 23, 188]\n",
            "[]\n",
            "[189, 56, 190, 191, 83, 23]\n",
            "[]\n",
            "[192, 43, 193, 194, 195, 196]\n",
            "[]\n",
            "[79, 197, 198, 199, 200]\n",
            "[]\n",
            "[201, 202, 203, 81, 204, 205]\n",
            "[]\n",
            "[206, 207, 208, 209, 210, 211, 56]\n",
            "[]\n",
            "[212, 213, 214, 78, 215]\n",
            "[]\n",
            "[216, 217, 218, 219]\n",
            "[]\n",
            "[82, 220, 85, 6, 86]\n",
            "[]\n",
            "[221, 5, 222, 223, 224, 225]\n",
            "[]\n",
            "[226, 5, 227, 52, 56]\n",
            "[]\n",
            "[228, 229, 230, 65, 231]\n",
            "[]\n",
            "[232, 233, 41, 14, 63, 234, 45, 235, 8, 15, 236, 76, 237, 11, 238, 239, 6, 86, 240]\n",
            "[]\n",
            "[241, 44, 242]\n",
            "[]\n",
            "[243, 54, 244, 5, 245, 4]\n",
            "[]\n",
            "[20, 85, 6, 246]\n",
            "[20, 247, 248, 249, 250, 55]\n",
            "[20, 54, 251, 84, 252]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence in faqs.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "4S2CRNM9tAgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdY6Q2M8uYa_",
        "outputId": "45cd0f3e-15ad-47e9-80b2-1fd95f1c2586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[57, 4],\n",
              " [57, 4, 87],\n",
              " [57, 4, 87, 88],\n",
              " [57, 4, 87, 88, 89],\n",
              " [90, 91],\n",
              " [90, 91, 92],\n",
              " [90, 91, 92, 58],\n",
              " [90, 91, 92, 58, 6],\n",
              " [90, 91, 92, 58, 6, 21],\n",
              " [90, 91, 92, 58, 6, 21, 59],\n",
              " [90, 91, 92, 58, 6, 21, 59, 93],\n",
              " [90, 91, 92, 58, 6, 21, 59, 93, 40],\n",
              " [41, 14],\n",
              " [94, 14],\n",
              " [60, 95],\n",
              " [60, 95, 22],\n",
              " [60, 95, 22, 42],\n",
              " [60, 95, 22, 42, 61],\n",
              " [60, 95, 22, 42, 61, 96],\n",
              " [60, 95, 22, 42, 61, 96, 62],\n",
              " [60, 95, 22, 42, 61, 96, 62, 23],\n",
              " [60, 95, 22, 42, 61, 96, 62, 23, 43],\n",
              " [4, 6],\n",
              " [4, 6, 97],\n",
              " [4, 6, 97, 21],\n",
              " [4, 6, 97, 21, 11],\n",
              " [4, 6, 97, 21, 11, 98],\n",
              " [4, 6, 97, 21, 11, 98, 44],\n",
              " [4, 6, 97, 21, 11, 98, 44, 63],\n",
              " [4, 6, 97, 21, 11, 98, 44, 63, 99],\n",
              " [4, 6, 97, 21, 11, 98, 44, 63, 99, 24],\n",
              " [4, 6, 97, 21, 11, 98, 44, 63, 99, 24, 5],\n",
              " [4, 6, 97, 21, 11, 98, 44, 63, 99, 24, 5, 64],\n",
              " [4, 6, 97, 21, 11, 98, 44, 63, 99, 24, 5, 64, 22],\n",
              " [4, 6, 97, 21, 11, 98, 44, 63, 99, 24, 5, 64, 22, 100],\n",
              " [4, 6, 97, 21, 11, 98, 44, 63, 99, 24, 5, 64, 22, 100, 25],\n",
              " [101, 102],\n",
              " [101, 102, 103],\n",
              " [101, 102, 103, 65],\n",
              " [101, 102, 103, 65, 104],\n",
              " [4, 66],\n",
              " [4, 66, 12],\n",
              " [4, 66, 12, 45],\n",
              " [4, 66, 12, 45, 11],\n",
              " [4, 66, 12, 45, 11, 8],\n",
              " [4, 66, 12, 45, 11, 8, 5],\n",
              " [4, 66, 12, 45, 11, 8, 5, 105],\n",
              " [4, 66, 12, 45, 11, 8, 5, 105, 67],\n",
              " [4, 66, 12, 45, 11, 8, 5, 105, 67, 6],\n",
              " [4, 66, 12, 45, 11, 8, 5, 105, 67, 6, 21],\n",
              " [4, 66, 12, 45, 11, 8, 5, 105, 67, 6, 21, 42],\n",
              " [106, 40],\n",
              " [106, 40, 107],\n",
              " [106, 40, 107, 108],\n",
              " [11, 8],\n",
              " [11, 8, 6],\n",
              " [11, 8, 6, 21],\n",
              " [11, 8, 6, 21, 109],\n",
              " [12, 110],\n",
              " [12, 110, 111],\n",
              " [112, 4],\n",
              " [112, 4, 113],\n",
              " [112, 4, 113, 114],\n",
              " [112, 4, 113, 114, 68],\n",
              " [112, 4, 113, 114, 68, 8],\n",
              " [58, 43],\n",
              " [58, 43, 115],\n",
              " [58, 43, 115, 3],\n",
              " [58, 43, 115, 3, 4],\n",
              " [58, 43, 115, 3, 4, 116],\n",
              " [69, 117],\n",
              " [118, 15],\n",
              " [118, 15, 119],\n",
              " [8, 15],\n",
              " [8, 15, 120],\n",
              " [26, 7],\n",
              " [26, 7, 22],\n",
              " [26, 7, 22, 46],\n",
              " [47, 24],\n",
              " [47, 24, 5],\n",
              " [47, 24, 5, 121],\n",
              " [47, 24, 5, 121, 70],\n",
              " [47, 24, 5, 121, 70, 11],\n",
              " [49, 32],\n",
              " [25, 122],\n",
              " [25, 122, 23],\n",
              " [25, 122, 23, 71],\n",
              " [25, 122, 23, 71, 7],\n",
              " [71, 9],\n",
              " [71, 9, 22],\n",
              " [71, 9, 22, 123],\n",
              " [7, 9],\n",
              " [7, 9, 124],\n",
              " [7, 9, 124, 125],\n",
              " [26, 72],\n",
              " [26, 72, 69],\n",
              " [26, 72, 69, 46],\n",
              " [47, 24],\n",
              " [47, 24, 126],\n",
              " [47, 24, 126, 42],\n",
              " [47, 24, 126, 42, 5],\n",
              " [47, 24, 126, 42, 5, 67],\n",
              " [49, 32],\n",
              " [50, 32],\n",
              " [26, 74],\n",
              " [26, 74, 8],\n",
              " [26, 74, 8, 15],\n",
              " [26, 74, 8, 15, 127],\n",
              " [26, 74, 8, 15, 127, 128],\n",
              " [26, 74, 8, 15, 127, 128, 75],\n",
              " [51, 44],\n",
              " [51, 44, 130],\n",
              " [51, 44, 130, 131],\n",
              " [51, 44, 130, 131, 76],\n",
              " [51, 44, 130, 131, 76, 14],\n",
              " [51, 44, 130, 131, 76, 14, 5],\n",
              " [51, 44, 130, 131, 76, 14, 5, 132],\n",
              " [51, 44, 130, 131, 76, 14, 5, 132, 9],\n",
              " [51, 44, 130, 131, 76, 14, 5, 132, 9, 133],\n",
              " [51, 44, 130, 131, 76, 14, 5, 132, 9, 133, 41],\n",
              " [51, 44, 130, 131, 76, 14, 5, 132, 9, 133, 41, 134],\n",
              " [26, 135],\n",
              " [26, 135, 25],\n",
              " [26, 135, 25, 46],\n",
              " [47, 24],\n",
              " [47, 24, 5],\n",
              " [47, 24, 5, 25],\n",
              " [49, 32],\n",
              " [136, 13],\n",
              " [137, 57],\n",
              " [137, 57, 4],\n",
              " [137, 57, 4, 138],\n",
              " [137, 57, 4, 138, 139],\n",
              " [137, 57, 4, 138, 139, 140],\n",
              " [8, 15],\n",
              " [8, 15, 141],\n",
              " [8, 15, 141, 142],\n",
              " [8, 15, 141, 142, 45],\n",
              " [8, 15, 141, 142, 45, 143],\n",
              " [8, 15, 141, 142, 45, 143, 77],\n",
              " [8, 15, 141, 142, 45, 143, 77, 14],\n",
              " [12, 144],\n",
              " [12, 144, 145],\n",
              " [12, 144, 145, 146],\n",
              " [147, 64],\n",
              " [147, 64, 59],\n",
              " [147, 64, 59, 148],\n",
              " [147, 64, 59, 148, 40],\n",
              " [147, 64, 59, 148, 40, 149],\n",
              " [147, 64, 59, 148, 40, 149, 62],\n",
              " [61, 68],\n",
              " [61, 68, 78],\n",
              " [61, 68, 78, 150],\n",
              " [61, 68, 78, 150, 79],\n",
              " [151, 4],\n",
              " [151, 4, 52],\n",
              " [151, 4, 52, 80],\n",
              " [151, 4, 52, 80, 52],\n",
              " [151, 4, 52, 80, 52, 53],\n",
              " [152, 80],\n",
              " [152, 80, 4],\n",
              " [152, 80, 4, 53],\n",
              " [6, 11],\n",
              " [6, 11, 20],\n",
              " [6, 11, 20, 51],\n",
              " [6, 11, 20, 51, 51],\n",
              " [12, 20],\n",
              " [12, 20, 74],\n",
              " [12, 20, 74, 12],\n",
              " [12, 20, 74, 12, 72],\n",
              " [12, 20, 74, 12, 72, 12],\n",
              " [153, 81],\n",
              " [153, 81, 154],\n",
              " [153, 81, 154, 155],\n",
              " [156, 157],\n",
              " [156, 157, 158],\n",
              " [156, 157, 158, 82],\n",
              " [156, 157, 158, 82, 159],\n",
              " [60, 53],\n",
              " [60, 53, 160],\n",
              " [60, 53, 160, 4],\n",
              " [60, 53, 160, 4, 83],\n",
              " [60, 53, 160, 4, 83, 54],\n",
              " [60, 53, 160, 4, 83, 54, 55],\n",
              " [60, 53, 160, 4, 83, 54, 55, 84],\n",
              " [60, 53, 160, 4, 83, 54, 55, 84, 161],\n",
              " [162, 163],\n",
              " [162, 163, 164],\n",
              " [162, 163, 164, 165],\n",
              " [162, 163, 164, 165, 166],\n",
              " [75, 77],\n",
              " [75, 77, 167],\n",
              " [75, 77, 167, 168],\n",
              " [169, 4],\n",
              " [169, 4, 9],\n",
              " [169, 4, 9, 170],\n",
              " [169, 4, 9, 170, 70],\n",
              " [169, 4, 9, 170, 70, 171],\n",
              " [169, 4, 9, 170, 70, 171, 172],\n",
              " [173, 4],\n",
              " [173, 4, 9],\n",
              " [173, 4, 9, 174],\n",
              " [173, 4, 9, 174, 175],\n",
              " [176, 9],\n",
              " [176, 9, 177],\n",
              " [176, 9, 177, 178],\n",
              " [176, 9, 177, 178, 55],\n",
              " [179, 4],\n",
              " [179, 4, 9],\n",
              " [179, 4, 9, 180],\n",
              " [179, 4, 9, 180, 181],\n",
              " [179, 4, 9, 180, 181, 182],\n",
              " [179, 4, 9, 180, 181, 182, 183],\n",
              " [184, 185],\n",
              " [184, 185, 66],\n",
              " [184, 185, 66, 186],\n",
              " [184, 185, 66, 186, 187],\n",
              " [184, 185, 66, 186, 187, 23],\n",
              " [184, 185, 66, 186, 187, 23, 188],\n",
              " [189, 56],\n",
              " [189, 56, 190],\n",
              " [189, 56, 190, 191],\n",
              " [189, 56, 190, 191, 83],\n",
              " [189, 56, 190, 191, 83, 23],\n",
              " [192, 43],\n",
              " [192, 43, 193],\n",
              " [192, 43, 193, 194],\n",
              " [192, 43, 193, 194, 195],\n",
              " [192, 43, 193, 194, 195, 196],\n",
              " [79, 197],\n",
              " [79, 197, 198],\n",
              " [79, 197, 198, 199],\n",
              " [79, 197, 198, 199, 200],\n",
              " [201, 202],\n",
              " [201, 202, 203],\n",
              " [201, 202, 203, 81],\n",
              " [201, 202, 203, 81, 204],\n",
              " [201, 202, 203, 81, 204, 205],\n",
              " [206, 207],\n",
              " [206, 207, 208],\n",
              " [206, 207, 208, 209],\n",
              " [206, 207, 208, 209, 210],\n",
              " [206, 207, 208, 209, 210, 211],\n",
              " [206, 207, 208, 209, 210, 211, 56],\n",
              " [212, 213],\n",
              " [212, 213, 214],\n",
              " [212, 213, 214, 78],\n",
              " [212, 213, 214, 78, 215],\n",
              " [216, 217],\n",
              " [216, 217, 218],\n",
              " [216, 217, 218, 219],\n",
              " [82, 220],\n",
              " [82, 220, 85],\n",
              " [82, 220, 85, 6],\n",
              " [82, 220, 85, 6, 86],\n",
              " [221, 5],\n",
              " [221, 5, 222],\n",
              " [221, 5, 222, 223],\n",
              " [221, 5, 222, 223, 224],\n",
              " [221, 5, 222, 223, 224, 225],\n",
              " [226, 5],\n",
              " [226, 5, 227],\n",
              " [226, 5, 227, 52],\n",
              " [226, 5, 227, 52, 56],\n",
              " [228, 229],\n",
              " [228, 229, 230],\n",
              " [228, 229, 230, 65],\n",
              " [228, 229, 230, 65, 231],\n",
              " [232, 233],\n",
              " [232, 233, 41],\n",
              " [232, 233, 41, 14],\n",
              " [232, 233, 41, 14, 63],\n",
              " [232, 233, 41, 14, 63, 234],\n",
              " [232, 233, 41, 14, 63, 234, 45],\n",
              " [232, 233, 41, 14, 63, 234, 45, 235],\n",
              " [232, 233, 41, 14, 63, 234, 45, 235, 8],\n",
              " [232, 233, 41, 14, 63, 234, 45, 235, 8, 15],\n",
              " [232, 233, 41, 14, 63, 234, 45, 235, 8, 15, 236],\n",
              " [232, 233, 41, 14, 63, 234, 45, 235, 8, 15, 236, 76],\n",
              " [232, 233, 41, 14, 63, 234, 45, 235, 8, 15, 236, 76, 237],\n",
              " [232, 233, 41, 14, 63, 234, 45, 235, 8, 15, 236, 76, 237, 11],\n",
              " [232, 233, 41, 14, 63, 234, 45, 235, 8, 15, 236, 76, 237, 11, 238],\n",
              " [232, 233, 41, 14, 63, 234, 45, 235, 8, 15, 236, 76, 237, 11, 238, 239],\n",
              " [232, 233, 41, 14, 63, 234, 45, 235, 8, 15, 236, 76, 237, 11, 238, 239, 6],\n",
              " [232,\n",
              "  233,\n",
              "  41,\n",
              "  14,\n",
              "  63,\n",
              "  234,\n",
              "  45,\n",
              "  235,\n",
              "  8,\n",
              "  15,\n",
              "  236,\n",
              "  76,\n",
              "  237,\n",
              "  11,\n",
              "  238,\n",
              "  239,\n",
              "  6,\n",
              "  86],\n",
              " [232,\n",
              "  233,\n",
              "  41,\n",
              "  14,\n",
              "  63,\n",
              "  234,\n",
              "  45,\n",
              "  235,\n",
              "  8,\n",
              "  15,\n",
              "  236,\n",
              "  76,\n",
              "  237,\n",
              "  11,\n",
              "  238,\n",
              "  239,\n",
              "  6,\n",
              "  86,\n",
              "  240],\n",
              " [241, 44],\n",
              " [241, 44, 242],\n",
              " [243, 54],\n",
              " [243, 54, 244],\n",
              " [243, 54, 244, 5],\n",
              " [243, 54, 244, 5, 245],\n",
              " [243, 54, 244, 5, 245, 4],\n",
              " [20, 85],\n",
              " [20, 85, 6],\n",
              " [20, 85, 6, 246],\n",
              " [20, 247],\n",
              " [20, 247, 248],\n",
              " [20, 247, 248, 249],\n",
              " [20, 247, 248, 249, 250],\n",
              " [20, 247, 248, 249, 250, 55],\n",
              " [20, 54],\n",
              " [20, 54, 251],\n",
              " [20, 54, 251, 84],\n",
              " [20, 54, 251, 84, 252]]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequences])\n",
        "print(max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls0v4BgguclE",
        "outputId": "3f860102-26d1-43b1-8a0a-1dcfa2d78bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
      ],
      "metadata": {
        "id": "SYMjzMLgvHTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(padded_input_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gcMVzk4vNm2",
        "outputId": "451c611e-9bfe-4433-88a6-eb590288ca42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0 ...   0  57   4]\n",
            " [  0   0   0 ...  57   4  87]\n",
            " [  0   0   0 ...   4  87  88]\n",
            " ...\n",
            " [  0   0   0 ...  20  54 251]\n",
            " [  0   0   0 ...  54 251  84]\n",
            " [  0   0   0 ... 251  84 252]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequences[:,:-1]\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW5CAL5lvY6o",
        "outputId": "bb62f741-86bc-4157-e21d-00d70d44a1fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   0,  57],\n",
              "       [  0,   0,   0, ...,   0,  57,   4],\n",
              "       [  0,   0,   0, ...,  57,   4,  87],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   0,  20,  54],\n",
              "       [  0,   0,   0, ...,  20,  54, 251],\n",
              "       [  0,   0,   0, ...,  54, 251,  84]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = padded_input_sequences[:,-1]\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-IDAT9lvqeW",
        "outputId": "58842925-dcf6-438f-b4fe-5b0db6e0db82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  4,  87,  88,  89,  91,  92,  58,   6,  21,  59,  93,  40,  14,\n",
              "        14,  95,  22,  42,  61,  96,  62,  23,  43,   6,  97,  21,  11,\n",
              "        98,  44,  63,  99,  24,   5,  64,  22, 100,  25, 102, 103,  65,\n",
              "       104,  66,  12,  45,  11,   8,   5, 105,  67,   6,  21,  42,  40,\n",
              "       107, 108,   8,   6,  21, 109, 110, 111,   4, 113, 114,  68,   8,\n",
              "        43, 115,   3,   4, 116, 117,  15, 119,  15, 120,   7,  22,  46,\n",
              "        24,   5, 121,  70,  11,  32, 122,  23,  71,   7,   9,  22, 123,\n",
              "         9, 124, 125,  72,  69,  46,  24, 126,  42,   5,  67,  32,  32,\n",
              "        74,   8,  15, 127, 128,  75,  44, 130, 131,  76,  14,   5, 132,\n",
              "         9, 133,  41, 134, 135,  25,  46,  24,   5,  25,  32,  13,  57,\n",
              "         4, 138, 139, 140,  15, 141, 142,  45, 143,  77,  14, 144, 145,\n",
              "       146,  64,  59, 148,  40, 149,  62,  68,  78, 150,  79,   4,  52,\n",
              "        80,  52,  53,  80,   4,  53,  11,  20,  51,  51,  20,  74,  12,\n",
              "        72,  12,  81, 154, 155, 157, 158,  82, 159,  53, 160,   4,  83,\n",
              "        54,  55,  84, 161, 163, 164, 165, 166,  77, 167, 168,   4,   9,\n",
              "       170,  70, 171, 172,   4,   9, 174, 175,   9, 177, 178,  55,   4,\n",
              "         9, 180, 181, 182, 183, 185,  66, 186, 187,  23, 188,  56, 190,\n",
              "       191,  83,  23,  43, 193, 194, 195, 196, 197, 198, 199, 200, 202,\n",
              "       203,  81, 204, 205, 207, 208, 209, 210, 211,  56, 213, 214,  78,\n",
              "       215, 217, 218, 219, 220,  85,   6,  86,   5, 222, 223, 224, 225,\n",
              "         5, 227,  52,  56, 229, 230,  65, 231, 233,  41,  14,  63, 234,\n",
              "        45, 235,   8,  15, 236,  76, 237,  11, 238, 239,   6,  86, 240,\n",
              "        44, 242,  54, 244,   5, 245,   4,  85,   6, 246, 247, 248, 249,\n",
              "       250,  55,  54, 251,  84, 252], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y,num_classes=283)"
      ],
      "metadata": {
        "id": "DOTi1a8gvtDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n5IbV5paw7SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ5IfD1kxqvU",
        "outputId": "b7e96c47-0454-4e5b-b8aa-20c1b06614f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(305, 283)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "cwPN_0rtyAaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(283, 100))\n",
        "model.add(LSTM(150, return_sequences=True))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(283, activation='softmax'))"
      ],
      "metadata": {
        "id": "Bo_YC2-ryWpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "dxTAl1dhymyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "eAfGmz0Gyphf",
        "outputId": "b84fcfe1-5579-4650-cdd9-e2c503a1029c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         ‚îÇ ?                      ‚îÇ   \u001b[38;5;34m0\u001b[0m (unbuilt) ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   ‚îÇ ?                      ‚îÇ   \u001b[38;5;34m0\u001b[0m (unbuilt) ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   ‚îÇ ?                      ‚îÇ   \u001b[38;5;34m0\u001b[0m (unbuilt) ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ ?                      ‚îÇ   \u001b[38;5;34m0\u001b[0m (unbuilt) ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         ‚îÇ ?                      ‚îÇ   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   ‚îÇ ?                      ‚îÇ   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   ‚îÇ ?                      ‚îÇ   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ ?                      ‚îÇ   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeYi9E1UyrPm",
        "outputId": "f5506f94-5c9f-42f6-d073-7bababd65d8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.0066 - loss: 5.6427\n",
            "Epoch 2/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.0355 - loss: 5.5007\n",
            "Epoch 3/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.0308 - loss: 5.2670\n",
            "Epoch 4/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.0570 - loss: 5.0851\n",
            "Epoch 5/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.0558 - loss: 5.0437\n",
            "Epoch 6/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.0192 - loss: 5.1139\n",
            "Epoch 7/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.0289 - loss: 5.1109\n",
            "Epoch 8/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.0282 - loss: 5.0302\n",
            "Epoch 9/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.0505 - loss: 5.0429\n",
            "Epoch 10/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.0348 - loss: 5.0079\n",
            "Epoch 11/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.0262 - loss: 5.0266\n",
            "Epoch 12/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 125ms/step - accuracy: 0.0379 - loss: 5.0377\n",
            "Epoch 13/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.0509 - loss: 4.9208\n",
            "Epoch 14/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.0519 - loss: 4.8729\n",
            "Epoch 15/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.0369 - loss: 4.8003\n",
            "Epoch 16/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.0508 - loss: 4.7772\n",
            "Epoch 17/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.0614 - loss: 4.6737\n",
            "Epoch 18/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.0355 - loss: 4.6544\n",
            "Epoch 19/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.0576 - loss: 4.5309\n",
            "Epoch 20/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.0657 - loss: 4.4253\n",
            "Epoch 21/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.0591 - loss: 4.4022\n",
            "Epoch 22/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.0707 - loss: 4.4126\n",
            "Epoch 23/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.0731 - loss: 4.3070\n",
            "Epoch 24/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.0709 - loss: 4.2644\n",
            "Epoch 25/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.0653 - loss: 4.2346\n",
            "Epoch 26/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.0912 - loss: 4.2275\n",
            "Epoch 27/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.0981 - loss: 4.1088\n",
            "Epoch 28/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.1106 - loss: 4.0801\n",
            "Epoch 29/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.1413 - loss: 3.9632\n",
            "Epoch 30/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.1276 - loss: 3.9112\n",
            "Epoch 31/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.0825 - loss: 4.0196\n",
            "Epoch 32/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.1227 - loss: 3.8332\n",
            "Epoch 33/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.1268 - loss: 3.8798\n",
            "Epoch 34/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.1430 - loss: 3.7554\n",
            "Epoch 35/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.1479 - loss: 3.7100\n",
            "Epoch 36/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.1589 - loss: 3.6747\n",
            "Epoch 37/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.1574 - loss: 3.6647\n",
            "Epoch 38/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.1806 - loss: 3.6216\n",
            "Epoch 39/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.2035 - loss: 3.5289\n",
            "Epoch 40/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 0.2269 - loss: 3.4270\n",
            "Epoch 41/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.2301 - loss: 3.3715\n",
            "Epoch 42/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.2476 - loss: 3.3371\n",
            "Epoch 43/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.2261 - loss: 3.3352\n",
            "Epoch 44/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.2542 - loss: 3.2593\n",
            "Epoch 45/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.2791 - loss: 3.1478\n",
            "Epoch 46/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.3041 - loss: 3.0867\n",
            "Epoch 47/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.3478 - loss: 3.0144\n",
            "Epoch 48/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.3402 - loss: 2.9572\n",
            "Epoch 49/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.3459 - loss: 3.0357\n",
            "Epoch 50/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.3985 - loss: 2.8879\n",
            "Epoch 51/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.3868 - loss: 2.8270\n",
            "Epoch 52/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 137ms/step - accuracy: 0.4195 - loss: 2.7178\n",
            "Epoch 53/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.3914 - loss: 2.7377\n",
            "Epoch 54/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.4379 - loss: 2.7030\n",
            "Epoch 55/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.4092 - loss: 2.7116\n",
            "Epoch 56/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.4745 - loss: 2.5588\n",
            "Epoch 57/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.5207 - loss: 2.4468\n",
            "Epoch 58/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.4644 - loss: 2.5731\n",
            "Epoch 59/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.5435 - loss: 2.4184\n",
            "Epoch 60/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.5263 - loss: 2.4091\n",
            "Epoch 61/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.5503 - loss: 2.3211\n",
            "Epoch 62/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.5453 - loss: 2.3230\n",
            "Epoch 63/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.5456 - loss: 2.2612\n",
            "Epoch 64/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.5632 - loss: 2.1686\n",
            "Epoch 65/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.5955 - loss: 2.0883\n",
            "Epoch 66/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.6064 - loss: 2.1301\n",
            "Epoch 67/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.5899 - loss: 2.0948\n",
            "Epoch 68/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.6231 - loss: 1.9966\n",
            "Epoch 69/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.6560 - loss: 1.9455\n",
            "Epoch 70/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.6468 - loss: 1.9178\n",
            "Epoch 71/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.6490 - loss: 1.9189\n",
            "Epoch 72/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.6857 - loss: 1.8362\n",
            "Epoch 73/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.7031 - loss: 1.8490\n",
            "Epoch 74/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.6877 - loss: 1.7759\n",
            "Epoch 75/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.7292 - loss: 1.6809\n",
            "Epoch 76/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7248 - loss: 1.6937\n",
            "Epoch 77/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7319 - loss: 1.6626\n",
            "Epoch 78/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - accuracy: 0.7212 - loss: 1.5892\n",
            "Epoch 79/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 0.7703 - loss: 1.5292\n",
            "Epoch 80/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.7373 - loss: 1.5948\n",
            "Epoch 81/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7690 - loss: 1.5297\n",
            "Epoch 82/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7508 - loss: 1.4808\n",
            "Epoch 83/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.7674 - loss: 1.4455\n",
            "Epoch 84/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.7497 - loss: 1.4904\n",
            "Epoch 85/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.7508 - loss: 1.4138\n",
            "Epoch 86/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7746 - loss: 1.3927\n",
            "Epoch 87/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.8187 - loss: 1.2768\n",
            "Epoch 88/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.8145 - loss: 1.2423\n",
            "Epoch 89/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8207 - loss: 1.2307\n",
            "Epoch 90/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8106 - loss: 1.2702\n",
            "Epoch 91/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.7881 - loss: 1.2831\n",
            "Epoch 92/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 0.8203 - loss: 1.1683\n",
            "Epoch 93/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.8212 - loss: 1.1627\n",
            "Epoch 94/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8156 - loss: 1.1950\n",
            "Epoch 95/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.8187 - loss: 1.1474\n",
            "Epoch 96/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.8284 - loss: 1.0676\n",
            "Epoch 97/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.8227 - loss: 1.1039\n",
            "Epoch 98/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.8359 - loss: 1.0413\n",
            "Epoch 99/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8641 - loss: 0.9628\n",
            "Epoch 100/100\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.8419 - loss: 1.0151\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78992e438fe0>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EMlFLymV0yMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "text = \"RNNs fail at\"\n",
        "\n",
        "for i in range(10):\n",
        "  # tokenize\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  # padding\n",
        "  padded_token_text = pad_sequences([token_text], maxlen=56, padding='pre')\n",
        "  # predict\n",
        "  pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n",
        "      time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M1bwg1EzfCt",
        "outputId": "4e76935b-82c2-447a-812f-c25e5354aee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step\n",
            "RNNs fail at 0\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "RNNs fail at 0 1\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
            "RNNs fail at 0 1 long\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "RNNs fail at 0 1 long term\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "RNNs fail at 0 1 long term dependencies\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "RNNs fail at 0 1 long term dependencies because\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "RNNs fail at 0 1 long term dependencies because of\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
            "RNNs fail at 0 1 long term dependencies because of because\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "RNNs fail at 0 1 long term dependencies because of because of\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
            "RNNs fail at 0 1 long term dependencies because of because of by\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z42zLA8T4BwW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}